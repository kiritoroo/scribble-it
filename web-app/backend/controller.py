import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' 

from fastapi import APIRouter, Form
from tensorflow import keras
import numpy as np
import base64
import cv2
import json

""" Load digits model & characters model """
model_digits = keras.models.load_model('./models/model_digits.h5')
model_characters = keras.models.load_model('./models/model_characters.h5')

keras_router = APIRouter(prefix='/api', tags=['Keras'])

""" Endpoint for Digits Handwriting Predict """
@keras_router.post('/predict_digits')
async def predict_digits(
  image_name: str = Form(...),
  image_base64_encode: str = Form(...)
) -> dict:
  """ ·∫¢nh ƒë·∫ßu v√†o c√≥ ƒë·ªãnh d·∫°ng RGBA, k√≠ch th∆∞·ªõc 400 x 400 """
  """ Predict Pipeline """
  # üéÑ Step 1: Decode chu·ªói ƒë·ªãnh d·∫°ng base64
  image_base64 = image_base64_encode.split(';base64,').pop()
  image_base64_decode = base64.b64decode(image_base64)

  # üéÑ Step 2: Chuy·ªÉn ƒë·ªãnh d·∫°ng base64 th√†nh h√¨nh ·∫£nh opencv
  image_array = np.frombuffer(image_base64_decode, dtype=np.uint8)
  image = cv2.imdecode(image_array, flags=cv2.IMREAD_UNCHANGED)

  # üéÑ Step 3: Thay n·ªÅn trong su·ªët -> n·ªÅn ƒëen
  B, G, R, A = cv2.split(image)
  alpha = A / 255
  R = (255 * (1 - alpha) + R * alpha).astype(np.uint8)
  G = (255 * (1 - alpha) + G * alpha).astype(np.uint8)
  B = (255 * (1 - alpha) + B * alpha).astype(np.uint8)
  image = cv2.merge((B, G, R))

  # üéÑ Step 4: Resize ·∫£nh th√†nh 28 x 28
  IMG_WIDTH = IMG_HEIGHT = 28
  dim = (IMG_WIDTH, IMG_HEIGHT)
  image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)

  # üéÑ Step 5: Predict
  image = np.invert(np.array([image[:,:,0]]))
  prediction = model_digits.predict(image)
  print("Predict digits handwriting")
  print(prediction)
  print("The number is probably a {}". format(np.argmax(prediction)))

  """ Response t·ªâ l·ªá c·ªßa t·∫•t c·∫£ c√°c s·ªë & s·ªë c√≥ t·ªâ l·ªá cao nh·∫•t """
  return { 
    "result_probably": int(np.argmax(prediction)),
    "result_all": prediction.tolist()
  }

""" Endpoint for Characters Handwriting Predict """
@keras_router.post('/predict_characters')
async def predict_characters(
  image_name: str = Form(...),
  image_base64_encode: str = Form(...)
) -> dict:
  """ ·∫¢nh ƒë·∫ßu v√†o c√≥ ƒë·ªãnh d·∫°ng RGBA, k√≠ch th∆∞·ªõc 400 x 400 """
  """ Predict Pipeline """
  # üéÑ Step 1: Decode chu·ªói ƒë·ªãnh d·∫°ng base64
  image_base64 = image_base64_encode.split(';base64,').pop()
  image_base64_decode = base64.b64decode(image_base64)

  # üéÑ Step 2: Chuy·ªÉn ƒë·ªãnh d·∫°ng base64 th√†nh h√¨nh ·∫£nh opencv
  image_array = np.frombuffer(image_base64_decode, dtype=np.uint8)
  image = cv2.imdecode(image_array, flags=cv2.IMREAD_UNCHANGED)

  # üéÑ Step 3: Thay n·ªÅn trong su·ªët -> n·ªÅn ƒëen
  B, G, R, A = cv2.split(image)
  alpha = A / 255
  R = (255 * (1 - alpha) + R * alpha).astype(np.uint8)
  G = (255 * (1 - alpha) + G * alpha).astype(np.uint8)
  B = (255 * (1 - alpha) + B * alpha).astype(np.uint8)
  image = cv2.merge((B, G, R))

  # üéÑ Step 4: Resize ·∫£nh th√†nh 28 x 28
  IMG_WIDTH = IMG_HEIGHT = 28
  dim = (IMG_WIDTH, IMG_HEIGHT)
  image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)

  # üéÑ Step 5: Predict
  image = np.invert(np.array([image[:,:,0]]))
  prediction = model_characters.predict(image)
  print("Predict characters handwriting")
  print(prediction)
  print("The number is probably a {}". format(np.argmax(prediction)+1))

  """ Response t·ªâ l·ªá c·ªßa t·∫•t c·∫£ c√°c s·ªë & s·ªë c√≥ t·ªâ l·ªá cao nh·∫•t"""
  return { 
    "result_probably": int(np.argmax(prediction)+1),
    "result_all": prediction.tolist()
  }